import os
import json
import streamlit as st
import networkx as nx
from pyvis.network import Network
import openai
import PyPDF2

# JSONãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒŠãƒ¬ãƒƒã‚¸DBã®ä¿å­˜å…ˆï¼‰
KNOWLEDGE_DB_FILE = "knowledge_db.json"

def load_knowledge_db():
    """
    ä¿å­˜æ¸ˆã¿ã®ãƒŠãƒ¬ãƒƒã‚¸DB(JSON)ã‚’èª­ã¿è¾¼ã‚€
    ç„¡ã‘ã‚Œã°åˆæœŸæ§‹é€ ã‚’è¿”ã™
    """
    if os.path.exists(KNOWLEDGE_DB_FILE):
        with open(KNOWLEDGE_DB_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return {"documents": [], "graph": {"nodes": [], "edges": []}}

def save_knowledge_db(db):
    """
    ãƒŠãƒ¬ãƒƒã‚¸DBã‚’JSONå½¢å¼ã§ä¿å­˜
    """
    with open(KNOWLEDGE_DB_FILE, "w", encoding="utf-8") as f:
        json.dump(db, f, ensure_ascii=False, indent=2)

def extract_text_from_pdf(pdf_file) -> str:
    """
    PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«é–¢æ•°
    """
    reader = PyPDF2.PdfReader(pdf_file)
    text_pages = []
    for page in reader.pages:
        text_pages.append(page.extract_text() or "")
    return "\n".join(text_pages)

def call_openai_for_metadata(text: str):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹è¨±æ–‡æ›¸ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰
    - (1)è¦ç´„
    - (2)ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    - (3)é‡è¦ãªé–¢ä¿‚æ€§ (ä¾‹: ç™ºæ˜è€…, å¯¾è±¡åˆ†é‡, etc.)
    ã‚’æŠ½å‡ºã™ã‚‹ä¾‹ã€‚
    
    å®Ÿéš›ã«ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚’å·¥å¤«ã—ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ˜ç¢ºã«æŒ‡ç¤ºã™ã‚‹ã€‚
    """
    prompt = f"""
ã‚ãªãŸã¯å„ªç§€ãªç‰¹è¨±ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ç‰¹è¨±æ–‡æ›¸ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

1) "summary": æ–‡ç« å…¨ä½“ã®è¦ç´„
2) "keywords": ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼åˆ†é‡ã®ãƒªã‚¹ãƒˆ
3) "entities": ç™ºæ˜è€…ã€å‡ºé¡˜ç•ªå·ã€å…¬é–‹æ—¥ãªã©é‡è¦æƒ…å ±ã‚’ã¾ã¨ã‚ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

ç‰¹è¨±ãƒ†ã‚­ã‚¹ãƒˆ:
{text}
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # ã¾ãŸã¯ "gpt-4"
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ç‰¹è¨±æ–‡æ›¸ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1000
        )
        result_text = response.choices[0].message["content"].strip()

        # JSONå½¢å¼ã§è¿”ã™æƒ³å®šãªã®ã§ã€ãƒ‘ãƒ¼ã‚¹
        metadata = json.loads(result_text)
        return metadata

    except Exception as e:
        st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_knowledge_db(db, metadata, original_text):
    """
    æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸DB(db)ã«æ–°ãŸã«ç‰¹è¨±æ–‡æ›¸ã®æƒ…å ±ã‚’è¿½åŠ ã—ã€
    ã‚°ãƒ©ãƒ•(nodes/edges)ã‚‚æ›´æ–°ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã€‚
    
    metadata: {"summary": "...", "keywords": [...], "entities": {...}}
    original_text: PDFã‹ã‚‰æŠ½å‡ºã—ãŸå…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ
    """
    # æ–‡æ›¸IDã‚’é©å½“ã«ç™ºè¡Œ
    doc_id = f"doc_{len(db['documents'])+1}"

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ 
    doc_entry = {
        "id": doc_id,
        "summary": metadata.get("summary", ""),
        "keywords": metadata.get("keywords", []),
        "entities": metadata.get("entities", {}),
        "fulltext": original_text
    }
    db["documents"].append(doc_entry)

    # ã‚°ãƒ©ãƒ•æƒ…å ±ã‚’æ›´æ–°
    # ã“ã“ã§ã¯ "doc_id" ãƒãƒ¼ãƒ‰ ã¨ "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"ãƒãƒ¼ãƒ‰ã‚’çµã¶ç°¡æ˜“ä¾‹
    if doc_id not in [n["id"] for n in db["graph"]["nodes"]]:
        db["graph"]["nodes"].append({
            "id": doc_id,
            "label": doc_id,
            "group": "document"
        })

    for kw in metadata.get("keywords", []):
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒ¼ãƒ‰ãŒæœªè¿½åŠ ãªã‚‰è¿½åŠ 
        if kw not in [n["id"] for n in db["graph"]["nodes"]]:
            db["graph"]["nodes"].append({
                "id": kw,
                "label": kw,
                "group": "keyword"
            })
        # ã‚¨ãƒƒã‚¸è¿½åŠ 
        db["graph"]["edges"].append({
            "source": doc_id,
            "target": kw,
            "label": "has_keyword"
        })

    return db

def visualize_knowledge_graph(db):
    """
    PyVisã‚’ä½¿ã£ã¦ãƒŠãƒ¬ãƒƒã‚¸DBä¸­ã®ãƒãƒ¼ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸ã‚’æç”»ã™ã‚‹
    """
    net = Network(height="600px", width="100%", directed=False)
    
    # ãƒãƒ¼ãƒ‰è¿½åŠ 
    for n in db["graph"]["nodes"]:
        net.add_node(
            n["id"],
            label=n["label"],
            title=f"{n['id']} (group: {n['group']})",
            group=n["group"]
        )
    
    # ã‚¨ãƒƒã‚¸è¿½åŠ 
    for e in db["graph"]["edges"]:
        net.add_edge(
            e["source"],
            e["target"],
            title=e["label"]
        )
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    net.force_atlas_2based()

    net.save_graph("graph.html")

    # Streamlitã«åŸ‹ã‚è¾¼ã‚€
    with open("graph.html", "r", encoding="utf-8") as f:
        html_content = f.read()
        st.components.v1.html(html_content, height=600, scrolling=True)

def main():
    st.title("ç‰¹è¨±ãƒŠãƒ¬ãƒƒã‚¸DBã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ & å¯è¦–åŒ–ãƒ‡ãƒ¢")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥åŠ›ã•ã›ã‚‹
    openai_api_key = st.text_input("OpenAI API Key", type="password")
    if not openai_api_key:
        st.info("Please enter your OpenAI API key to continue.", icon="ğŸ—ï¸")
        st.stop()

    # å…¥åŠ›ã•ã‚ŒãŸã‚­ãƒ¼ã‚’ã‚»ãƒƒãƒˆ
    openai.api_key = openai_api_key

    # 1. ãƒŠãƒ¬ãƒƒã‚¸DBèª­è¾¼ã¿
    db = load_knowledge_db()

    st.subheader("1. ç‰¹è¨±æ–‡æ›¸(PDF)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["pdf"])

    if uploaded_file is not None:
        text = extract_text_from_pdf(uploaded_file)
        st.write("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")

        if st.button("2. OpenAI APIã§è§£æã—ã€ãƒŠãƒ¬ãƒƒã‚¸DBã‚’æ›´æ–°"):
            with st.spinner("OpenAI APIã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­..."):
                metadata = call_openai_for_metadata(text)
                if metadata:
                    st.success("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸï¼")
                    st.json(metadata)  # æŠ½å‡ºçµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼

                    updated_db = update_knowledge_db(db, metadata, text)
                    save_knowledge_db(updated_db)
                    st.success("ãƒŠãƒ¬ãƒƒã‚¸DBã‚’æ›´æ–°ã—ã€JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

                    # ãƒ¡ãƒ¢ãƒªä¸Šã®dbã‚‚æ›´æ–°ã—ã¦ãŠã
                    db = updated_db

    st.subheader("3. ãƒŠãƒ¬ãƒƒã‚¸DBã®å†…å®¹ã‚’è¡¨ç¤º")
    st.write(f"ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(db['documents'])}")
    if st.checkbox("ãƒŠãƒ¬ãƒƒã‚¸DB(JSON)ã®ä¸­èº«ã‚’è¡¨ç¤ºã™ã‚‹"):
        st.json(db)

    st.subheader("4. ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’å¯è¦–åŒ–")
    if st.button("ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º"):
        visualize_knowledge_graph(db)

if __name__ == "__main__":
    main()
