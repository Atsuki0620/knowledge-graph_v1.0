import os
import json
import streamlit as st
import networkx as nx
from pyvis.network import Network
import openai
import PyPDF2

# JSONãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒŠãƒ¬ãƒƒã‚¸DBã®ä¿å­˜å…ˆï¼‰
KNOWLEDGE_DB_FILE = "knowledge_db.json"

def load_knowledge_db():
    """ä¿å­˜æ¸ˆã¿ã®ãƒŠãƒ¬ãƒƒã‚¸DB(JSON)ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(KNOWLEDGE_DB_FILE):
        with open(KNOWLEDGE_DB_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return {"documents": [], "graph": {"nodes": [], "edges": []}}

def save_knowledge_db(db):
    """ãƒŠãƒ¬ãƒƒã‚¸DBã‚’JSONå½¢å¼ã§ä¿å­˜"""
    with open(KNOWLEDGE_DB_FILE, "w", encoding="utf-8") as f:
        json.dump(db, f, ensure_ascii=False, indent=2)

def extract_text_from_pdf(pdf_file) -> str:
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«é–¢æ•°"""
    reader = PyPDF2.PdfReader(pdf_file)
    text_list = []
    for page in reader.pages:
        text_list.append(page.extract_text() or "")
    return "\n".join(text_list)

def call_openai_for_metadata(text: str):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ»è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã©ã‚’æŠ½å‡ºã™ã‚‹ä¾‹ã€‚
    å®Ÿéš›ã«ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å·¥å¤«ã—ã¦æƒ…å ±æŠ½å‡ºã‚’è¡Œã†ã€‚
    """
    prompt = f"""
ã‚ãªãŸã¯ç‰¹è¨±æ–‡æ›¸ã®è¦ç´„ã¨ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æŠ½å‡ºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ç‰¹è¨±æ–‡æ›¸ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€(1) è¦ç´„ã€(2) ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€(3) é‡è¦ãªé–¢ä¿‚æ€§ï¼ˆç™ºæ˜è€…ã€å¯¾è±¡åˆ†é‡ãªã©ï¼‰ã‚’ç°¡æ½”ã«æŠ½å‡ºã—ã€
JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{text}
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # å¿…è¦ã«å¿œã˜ã¦ "gpt-4" ãªã©ã«å¤‰æ›´
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªç‰¹è¨±ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1000
        )
        result_text = response.choices[0].message["content"].strip()
        # OpenAIã‹ã‚‰ã®å‡ºåŠ›ã‚’JSONãƒ‘ãƒ¼ã‚¹ã—ã¦è¿”ã™æƒ³å®š
        # ä¾‹: {"summary": "...", "keywords": [...], "entities": {...}}
        metadata = json.loads(result_text)  
        return metadata
    except Exception as e:
        st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_knowledge_db(db, metadata, original_text):
    """
    æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸DB(db)ã«æ–°ãŸãªç‰¹è¨±æ–‡æ›¸ã®æƒ…å ±ã‚’è¿½åŠ ã—ã€ã‚°ãƒ©ãƒ•æ§‹é€ ã‚‚æ›´æ–°
    metadata: {"summary": "...", "keywords": [...], "entities": {...}}
    original_text: ç‰¹è¨±å…¨æ–‡
    """
    # 1. æ–‡æ›¸IDã‚’ç™ºè¡Œï¼ˆç°¡æ˜“ï¼‰
    doc_id = f"doc_{len(db['documents'])+1}"

    # 2. documentsé…åˆ—ã«è¿½åŠ 
    doc_entry = {
        "id": doc_id,
        "summary": metadata.get("summary", ""),
        "keywords": metadata.get("keywords", []),
        "entities": metadata.get("entities", {}),
        "fulltext": original_text
    }
    db["documents"].append(doc_entry)

    # 3. ã‚°ãƒ©ãƒ•ï¼ˆnodes/edgesï¼‰ã®æ›´æ–°ä¾‹
    #    - ã“ã“ã§ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®IDã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµã¶ç°¡æ˜“çš„ãªãƒ¢ãƒ‡ãƒ«
    keywords = metadata.get("keywords", [])

    # docãƒãƒ¼ãƒ‰ãŒæœªå­˜åœ¨ãªã‚‰è¿½åŠ 
    if doc_id not in [n["id"] for n in db["graph"]["nodes"]]:
        db["graph"]["nodes"].append({
            "id": doc_id, "label": doc_id, "group": "document"
        })

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒãƒ¼ãƒ‰åŒ–
    for kw in keywords:
        if kw not in [n["id"] for n in db["graph"]["nodes"]]:
            db["graph"]["nodes"].append({
                "id": kw, "label": kw, "group": "keyword"
            })
        db["graph"]["edges"].append({
            "source": doc_id,
            "target": kw,
            "label": "has_keyword"
        })

    return db

def visualize_knowledge_graph(db):
    """PyVisã§ãƒŠãƒ¬ãƒƒã‚¸DBã®ã‚°ãƒ©ãƒ•ã‚’æç”»ã™ã‚‹"""
    nodes = db["graph"]["nodes"]
    edges = db["graph"]["edges"]

    net = Network(height="600px", width="100%", directed=False)

    # ãƒãƒ¼ãƒ‰è¿½åŠ 
    for n in nodes:
        net.add_node(
            n["id"],
            label=n["label"],
            title=f"{n['id']} (group: {n['group']})",
            group=n["group"]
        )

    # ã‚¨ãƒƒã‚¸è¿½åŠ 
    for e in edges:
        net.add_edge(
            e["source"],
            e["target"],
            title=e["label"]
        )

    # ç‰©ç†æ¼”ç®—ã«ã‚ˆã‚‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    net.force_atlas_2based()
    net.save_graph("graph.html")

    with open("graph.html", "r", encoding="utf-8") as f:
        html_content = f.read()
        st.components.v1.html(html_content, height=600, scrolling=True)

def main():
    st.title("ç‰¹è¨±ãƒŠãƒ¬ãƒƒã‚¸DBã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ & å¯è¦–åŒ–ãƒ‡ãƒ¢")

    # 0. ã‚¢ãƒ—ãƒªé–‹å§‹ç›´å¾Œã«OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã•ã›ã‚‹
    openai_api_key = st.text_input("OpenAI API Key", type="password")
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
        st.stop()
    
    # OpenAI APIã‚­ãƒ¼ã‚’ã‚»ãƒƒãƒˆ
    openai.api_key = openai_api_key

    # 1. ãƒŠãƒ¬ãƒƒã‚¸DBã‚’èª­è¾¼ã¿
    db = load_knowledge_db()

    # 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("1. ç‰¹è¨±æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["pdf"])

    if uploaded_file is not None:
        # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        text = extract_text_from_pdf(uploaded_file)

        if st.button("2. OpenAI APIã§è§£æã—ã€ãƒŠãƒ¬ãƒƒã‚¸DBã‚’æ›´æ–°"):
            with st.spinner("OpenAI APIã§è§£æä¸­..."):
                metadata = call_openai_for_metadata(text)
                if metadata:
                    st.success("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ!")
                    st.json(metadata)

                    # DBæ›´æ–°
                    updated_db = update_knowledge_db(db, metadata, text)
                    save_knowledge_db(updated_db)
                    st.success("ãƒŠãƒ¬ãƒƒã‚¸DBã‚’æ›´æ–°ã—ã€JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

                    # ãƒ¡ãƒ¢ãƒªä¸Šã®dbã‚’æ›´æ–°
                    db = updated_db

    st.subheader("3. ãƒŠãƒ¬ãƒƒã‚¸DBã®å†…å®¹ã‚’è¡¨ç¤º")
    # JSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if db["documents"]:
        st.write(f"ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(db['documents'])}")
        if st.checkbox("ãƒŠãƒ¬ãƒƒã‚¸DB(JSON)ã®ä¸­èº«ã‚’è¡¨ç¤ºã™ã‚‹"):
            st.json(db)

    st.subheader("4. ã‚°ãƒ©ãƒ•æ§‹é€ ã®å¯è¦–åŒ–")
    if st.button("ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º"):
        visualize_knowledge_graph(db)


if __name__ == "__main__":
    main()
